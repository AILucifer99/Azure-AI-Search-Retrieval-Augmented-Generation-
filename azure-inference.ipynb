{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f513716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import List\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import (\n",
    "    RunnablePassthrough,\n",
    "    RunnableLambda,\n",
    "    RunnableParallel\n",
    ")\n",
    "\n",
    "from azure.search.documents.models import VectorizedQuery\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d93b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomAzureSearchRetriever:\n",
    "    def __init__(self, search_client, embeddings, k: int = 5):\n",
    "        self.search_client = search_client\n",
    "        self.embeddings = embeddings\n",
    "        self.k = k\n",
    "\n",
    "    def __call__(self, query: str):\n",
    "        query_vector = self.embeddings.embed_query(query)\n",
    "\n",
    "        vector_query = VectorizedQuery(\n",
    "            vector=query_vector,\n",
    "            k_nearest_neighbors=self.k,\n",
    "            fields=\"content_vector\",\n",
    "            kind=\"vector\"\n",
    "        )\n",
    "\n",
    "        results = self.search_client.search(\n",
    "            search_text=query,\n",
    "            vector_queries=[vector_query],\n",
    "            select=[\n",
    "                \"id\", \"content\", \"source\", \"page\",\n",
    "                \"title\", \"author\", \"chunk_id\", \"metadata\"\n",
    "            ],\n",
    "            top=self.k\n",
    "        )\n",
    "\n",
    "        documents = []\n",
    "        for r in results:\n",
    "            metadata = {}\n",
    "            if r.get(\"metadata\"):\n",
    "                try:\n",
    "                    metadata = json.loads(r[\"metadata\"])\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            metadata.update({\n",
    "                \"source\": r.get(\"source\", \"\"),\n",
    "                \"page\": r.get(\"page\", 0),\n",
    "                \"title\": r.get(\"title\", \"\"),\n",
    "                \"author\": r.get(\"author\", \"\"),\n",
    "                \"chunk_id\": r.get(\"chunk_id\", 0),\n",
    "                \"score\": r.get(\"@search.score\", 0),\n",
    "            })\n",
    "\n",
    "            documents.append(\n",
    "                Document(\n",
    "                    page_content=r.get(\"content\", \"\"),\n",
    "                    metadata=metadata\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5bc4031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs_with_citations(docs: List[Document]) -> str:\n",
    "    formatted_chunks = []\n",
    "\n",
    "    for doc in docs:\n",
    "        page = doc.metadata.get(\"page\", \"N/A\")\n",
    "        source = os.path.basename(doc.metadata.get(\"source\", \"\"))\n",
    "\n",
    "        formatted_chunks.append(\n",
    "            f\"[Source: {source}, Page: {page}]\\n{doc.page_content}\"\n",
    "        )\n",
    "\n",
    "    return \"\\n\\n---\\n\\n\".join(formatted_chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7afc1219",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG_PROMPT = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "You are a knowledgeable assistant.\n",
    "Use ONLY the provided context to answer the question.\n",
    "Always cite page numbers in your answer.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer (with citations):\n",
    "\"\"\",\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f216af1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lcel_rag_chain(retriever: CustomAzureSearchRetriever):\n",
    "    llm = ChatOpenAI(\n",
    "        openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "        model=\"gpt-4.1-nano\",\n",
    "        temperature=0.3\n",
    "    )\n",
    "\n",
    "    rag_chain = (\n",
    "        RunnableParallel(\n",
    "            {\n",
    "                \"docs\": retriever,\n",
    "                \"question\": RunnablePassthrough(),\n",
    "            }\n",
    "        )\n",
    "        | RunnableLambda(\n",
    "            lambda x: {\n",
    "                \"context\": format_docs_with_citations(x[\"docs\"]),\n",
    "                \"question\": x[\"question\"],\n",
    "                \"source_documents\": x[\"docs\"],\n",
    "            }\n",
    "        )\n",
    "        | RunnableParallel(\n",
    "            {\n",
    "                \"answer\": RAG_PROMPT | llm | StrOutputParser(),\n",
    "                \"source_documents\": lambda x: x[\"source_documents\"],\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return rag_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d65c341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_rag_system(rag_chain, question: str):\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"â“ QUESTION: {question}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    result = rag_chain.invoke(question)\n",
    "\n",
    "    print(\"\\nğŸ’¡ ANSWER:\\n\")\n",
    "    print(result[\"answer\"])\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ“š SOURCES\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    for i, doc in enumerate(result[\"source_documents\"], 1):\n",
    "        print(f\"\\n--- Source {i} ---\")\n",
    "        print(f\"ğŸ“„ Page: {doc.metadata.get('page')}\")\n",
    "        print(f\"ğŸ“ File: {doc.metadata.get('source')}\")\n",
    "        print(f\"ğŸ“‹ Title: {doc.metadata.get('title')}\")\n",
    "        print(f\"ğŸ‘¤ Author: {doc.metadata.get('author')}\")\n",
    "        print(f\"ğŸ”¢ Chunk ID: {doc.metadata.get('chunk_id')}\")\n",
    "        print(f\"â­ Score: {doc.metadata.get('score')}\")\n",
    "        print(f\"\\nğŸ“– Content Preview:\\n{doc.page_content[:300]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1b2502f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_rag_inference(embeddings, top_k_documents):\n",
    "    search_client = SearchClient(\n",
    "        endpoint=os.getenv(\"AZURE_SEARCH_ENDPOINT\"),\n",
    "        index_name=os.getenv(\"AZURE_SEARCH_INDEX_NAME\"),\n",
    "        credential=AzureKeyCredential(os.getenv(\"AZURE_SEARCH_KEY\"))\n",
    "    )\n",
    "\n",
    "    retriever = CustomAzureSearchRetriever(\n",
    "        search_client=search_client,\n",
    "        embeddings=embeddings,\n",
    "        k=top_k_documents\n",
    "    )\n",
    "\n",
    "    rag_chain = build_lcel_rag_chain(retriever)\n",
    "    return rag_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc66d34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "â“ QUESTION: Generate a detailed summary along with key findings for the research paper starting from \n",
      "    the begining till the ending. Also provide citations and references if possible.\n",
      "================================================================================\n",
      "\n",
      "ğŸ’¡ ANSWER:\n",
      "\n",
      "The research paper \"Engineering the RAG Stack\" provides a comprehensive overview of Retrieval-Augmented Generation (RAG) systems, emphasizing their architectural components, capabilities, and design trade-offs. It begins by introducing the foundational concept of RAG, which integrates external retrieval mechanisms with generative models to enhance knowledge retrieval and response generation, surpassing traditional language models' limitations (Page 9).\n",
      "\n",
      "The canonical RAG architecture, initially devised by Lewis et al., combines a Dense Passage Retriever (DPR) with a sequence-to-sequence generator such as BART or T5. The retriever calculates similarity scores between queries and documents using inner product measures, retrieving the top-k relevant documents from a corpus. The generator then conditions on these documents to produce contextually relevant responses, with the process grounded in a probabilistic formulation that combines relevance priors with generation likelihood (Pages 10-11, 12).\n",
      "\n",
      "Several model configurations are discussed, including DPR + BART, DPR + T5, Fusion-in-Decoder (FiD), Atlas, and WebGPT, each with distinct strengths and limitations. For example, DPR + BART offers fast retrieval but limited citation control, whereas WebGPT provides source attribution but with latency considerations (Page 11). Architectural trade-offs such as retrieval efficiency, context length constraints, and grounding fidelity are highlighted, guiding the design of effective RAG systems.\n",
      "\n",
      "The paper explores advanced retrieval strategies like hierarchical and graph-based methods. RAPTOR employs recursive abstractive processing and tree-structured retrieval to improve multi-hop retrieval accuracy and memory efficiency by clustering documents via Gaussian Mixture Models and summarizing them hierarchically (Page 22, 61). Similarly, GraphRAG utilizes community-based hierarchies to organize knowledge, enhancing retrieval performance.\n",
      "\n",
      "In addition to retrieval strategies, the paper discusses the importance of evaluation metrics tailored to RAG systems. Traditional IR metrics like MRR and nDCG are complemented by RAG-specific measures such as Context Precision, Recall, and Chunk Attribution, which assess relevance, grounding, and source attribution accuracy. The TruLens framework introduces the RAG Triadâ€”context relevance, groundedness, and answer relevanceâ€”to detect hallucinations and improve model reliability (Page 30, 68).\n",
      "\n",
      "Application domains suitable for canonical RAG include question answering tasks based on Wikipedia, where the knowledge corpus aligns with training data, and query patterns are predictable. The architecture's effectiveness in these domains is attributed to its ability to retrieve empirical knowledge and generate concise responses efficiently (Page 9, 20).\n",
      "\n",
      "Overall, the paper emphasizes the importance of architectural choices, retrieval strategies, and evaluation metrics in designing robust RAG systems. It underscores ongoing challenges such as balancing recall and efficiency, grounding responses in retrieved evidence, and maintaining interpretability. The insights provided serve as a foundation for future research aimed at enhancing retrieval accuracy, reducing hallucinations, and expanding domain applicability (Pages 10-12, 22, 30, 68).\n",
      "\n",
      "References:\n",
      "- Lewis et al., â€œDense Passage Retrieval for Open-Domain QA,â€ EMNLP 2020 (Page 68)\n",
      "- Fan et al., â€œA Survey on Retrieval-Augmented LLMs,â€ KDD 2024 (Page 68)\n",
      "- Khattab and Zaharia, â€œColBERT,â€ SIGIR 2020 (Page 68)\n",
      "- Nogueira and Cho, â€œPassage Reranking with BERT,â€ arXiv 2019 (Page 68)\n",
      "- Pinecone, â€œRerankers and Two-Stage Retrieval,â€ 2024 (Page 68)\n",
      "\n",
      "================================================================================\n",
      "ğŸ“š SOURCES\n",
      "================================================================================\n",
      "\n",
      "--- Source 1 ---\n",
      "ğŸ“„ Page: 11\n",
      "ğŸ“ File: Data\\RAG-Papers-2025\\Engineering the RAG Stack.pdf\n",
      "ğŸ“‹ Title: Engineering the RAG Stack: A Comprehensive Review of the Architecture and Trust Frameworks for Retrieval-Augmented Generation Systems\n",
      "ğŸ‘¤ Author: Dean Wampler; Dave Nielson; Alireza Seddighi\n",
      "ğŸ”¢ Chunk ID: 29\n",
      "â­ Score: 0.03076923079788685\n",
      "\n",
      "ğŸ“– Content Preview:\n",
      "sive decoding and bidirectional encoder states. Token limitations in these\n",
      "models can introduce truncation artifacts that particularly affect long-form\n",
      "reasoning tasks requiring extensive context integration [41].\n",
      "3.3\n",
      "Empirical Characterization of the Canonical Pipeline\n",
      "Table 3.1: Canonical RAG Mode...\n",
      "\n",
      "--- Source 2 ---\n",
      "ğŸ“„ Page: 22\n",
      "ğŸ“ File: Data\\RAG-Papers-2025\\Engineering the RAG Stack.pdf\n",
      "ğŸ“‹ Title: Engineering the RAG Stack: A Comprehensive Review of the Architecture and Trust Frameworks for Retrieval-Augmented Generation Systems\n",
      "ğŸ‘¤ Author: Dean Wampler; Dave Nielson; Alireza Seddighi\n",
      "ğŸ”¢ Chunk ID: 56\n",
      "â­ Score: 0.026838432997465134\n",
      "\n",
      "ğŸ“– Content Preview:\n",
      "for reliable multi-hop retrieval [81].\n",
      "5.3.1\n",
      "RAPTOR and Tree-Structured Retrieval\n",
      "RAPTOR (Recursive Abstractive Processing for Tree-Organized Retrieval)\n",
      "represents a significant advancement in hierarchical RAG architectures,\n",
      "achieving substantial accuracy improvements on the QuALITY benchmark\n",
      "with G...\n",
      "\n",
      "--- Source 3 ---\n",
      "ğŸ“„ Page: 20\n",
      "ğŸ“ File: Data\\RAG-Papers-2025\\Engineering the RAG Stack.pdf\n",
      "ğŸ“‹ Title: Engineering the RAG Stack: A Comprehensive Review of the Architecture and Trust Frameworks for Retrieval-Augmented Generation Systems\n",
      "ğŸ‘¤ Author: Dean Wampler; Dave Nielson; Alireza Seddighi\n",
      "ğŸ”¢ Chunk ID: 50\n",
      "â­ Score: 0.023200757801532745\n",
      "\n",
      "ğŸ“– Content Preview:\n",
      "knowledge-intensive duties, is effectively addressed by RAG-Fusion.\n",
      "5.1.1Pipeline Architecture\n",
      "The RAG-Fusion pipeline is comprised of three stages: query diversification,\n",
      "parallel retrieval, and reciprocal rank fusion (RRF). The mathematical foun-\n",
      "dation is based on reciprocal rank fusion with para...\n",
      "\n",
      "--- Source 4 ---\n",
      "ğŸ“„ Page: 10\n",
      "ğŸ“ File: Data\\RAG-Papers-2025\\Engineering the RAG Stack.pdf\n",
      "ğŸ“‹ Title: Engineering the RAG Stack: A Comprehensive Review of the Architecture and Trust Frameworks for Retrieval-Augmented Generation Systems\n",
      "ğŸ‘¤ Author: Dean Wampler; Dave Nielson; Alireza Seddighi\n",
      "ğŸ”¢ Chunk ID: 25\n",
      "â­ Score: 0.021641790866851807\n",
      "\n",
      "ğŸ“– Content Preview:\n",
      "Canonical RAG pipelines establish a closely integrated interaction between\n",
      "a differentiable retriever, which is typically based on dense vectors, and an\n",
      "autoregressive generator, such as BART or T5, resulting in a synergistic\n",
      "mechanism in which contextual relevance and generative fluency evolve\n",
      "conc...\n",
      "\n",
      "--- Source 5 ---\n",
      "ğŸ“„ Page: 30\n",
      "ğŸ“ File: Data\\RAG-Papers-2025\\Engineering the RAG Stack.pdf\n",
      "ğŸ“‹ Title: Engineering the RAG Stack: A Comprehensive Review of the Architecture and Trust Frameworks for Retrieval-Augmented Generation Systems\n",
      "ğŸ‘¤ Author: Dean Wampler; Dave Nielson; Alireza Seddighi\n",
      "ğŸ”¢ Chunk ID: 76\n",
      "â­ Score: 0.02142857201397419\n",
      "\n",
      "ğŸ“– Content Preview:\n",
      "Metric\n",
      "Cate-\n",
      "gory\n",
      "Metric\n",
      "Name\n",
      "Description\n",
      "Order\n",
      "Sensi-\n",
      "tivity\n",
      "Implementation\n",
      "Complexity\n",
      "Correlation\n",
      "with Human\n",
      "Judgment\n",
      "Traditional\n",
      "IR\n",
      "MRR\n",
      "Mean\n",
      "reciprocal\n",
      "rank\n",
      "Yes\n",
      "Low\n",
      "Medium\n",
      "Traditional\n",
      "IR\n",
      "nDCG@k\n",
      "Position-\n",
      "weighted\n",
      "relevance\n",
      "Yes\n",
      "Medium\n",
      "High\n",
      "RAG-\n",
      "specific\n",
      "Context\n",
      "Preci-\n",
      "sion\n",
      "Relevant\n",
      "chunks in\n",
      "conte...\n",
      "\n",
      "--- Source 6 ---\n",
      "ğŸ“„ Page: 20\n",
      "ğŸ“ File: Data\\RAG-Papers-2025\\Engineering the RAG Stack.pdf\n",
      "ğŸ“‹ Title: Engineering the RAG Stack: A Comprehensive Review of the Architecture and Trust Frameworks for Retrieval-Augmented Generation Systems\n",
      "ğŸ‘¤ Author: Dean Wampler; Dave Nielson; Alireza Seddighi\n",
      "ğŸ”¢ Chunk ID: 51\n",
      "â­ Score: 0.02105513960123062\n",
      "\n",
      "ğŸ“– Content Preview:\n",
      "Fusion template, which includes complete LangSmith monitoring integration\n",
      "[51].\n",
      "5.2\n",
      "RE-RAG\n",
      "(Re-Ranking\n",
      "Enhanced\n",
      "RAG):\n",
      "Precision\n",
      "Through Two-Stage Retrieval\n",
      "The RE-RAG (Re-ranking Enhanced RAG) system represents a significant\n",
      "improvement in retrieval system accuracy through the integration of so-\n",
      "phi...\n",
      "\n",
      "--- Source 7 ---\n",
      "ğŸ“„ Page: 68\n",
      "ğŸ“ File: Data\\RAG-Papers-2025\\Engineering the RAG Stack.pdf\n",
      "ğŸ“‹ Title: Engineering the RAG Stack: A Comprehensive Review of the Architecture and Trust Frameworks for Retrieval-Augmented Generation Systems\n",
      "ğŸ‘¤ Author: Dean Wampler; Dave Nielson; Alireza Seddighi\n",
      "ğŸ”¢ Chunk ID: 168\n",
      "â­ Score: 0.020648760721087456\n",
      "\n",
      "ğŸ“– Content Preview:\n",
      "[33] M. Lewis et al., â€œBART: Denoising Sequence-to-Sequence Pretraining,â€\n",
      "in Proc. ACL, 2020, pp. 7871â€“7880.\n",
      "[34] C. Raffel et al., â€œExploring the Limits of Transfer Learning with a\n",
      "Unified Text-to-Text Transformer,â€ J. Mach.\n",
      "Learn.\n",
      "Res., vol.\n",
      "21, pp.\n",
      "1â€“67, 2020.\n",
      "[35] W. Fan et al., â€œA Survey on Ret...\n",
      "\n",
      "--- Source 8 ---\n",
      "ğŸ“„ Page: 12\n",
      "ğŸ“ File: Data\\RAG-Papers-2025\\Engineering the RAG Stack.pdf\n",
      "ğŸ“‹ Title: Engineering the RAG Stack: A Comprehensive Review of the Architecture and Trust Frameworks for Retrieval-Augmented Generation Systems\n",
      "ğŸ‘¤ Author: Dean Wampler; Dave Nielson; Alireza Seddighi\n",
      "ğŸ”¢ Chunk ID: 30\n",
      "â­ Score: 0.019635820761322975\n",
      "\n",
      "ğŸ“– Content Preview:\n",
      "Dimension\n",
      "Canonical\n",
      "Choice\n",
      "Design Benefit\n",
      "Structural Limitation\n",
      "Retrieval\n",
      "DPR\n",
      "(bi-encoder)\n",
      "Sublinear retrieval\n",
      "at scale\n",
      "Reduced recall on\n",
      "lexical queries\n",
      "Fusion\n",
      "Concatenation\n",
      "Simplified interface\n",
      "Context length\n",
      "boundaries\n",
      "GenerationBART/T5\n",
      "Pretrained fluency\n",
      "Hallucination\n",
      "susceptibility\n",
      "Grounding Im...\n",
      "\n",
      "--- Source 9 ---\n",
      "ğŸ“„ Page: 9\n",
      "ğŸ“ File: Data\\RAG-Papers-2025\\Engineering the RAG Stack.pdf\n",
      "ğŸ“‹ Title: Engineering the RAG Stack: A Comprehensive Review of the Architecture and Trust Frameworks for Retrieval-Augmented Generation Systems\n",
      "ğŸ‘¤ Author: Dean Wampler; Dave Nielson; Alireza Seddighi\n",
      "ğŸ”¢ Chunk ID: 24\n",
      "â­ Score: 0.019357044249773026\n",
      "\n",
      "ğŸ“– Content Preview:\n",
      "frameworks that are elaborated upon in subsequent sections.\n",
      "3\n",
      "The Canonical RAG Pipeline\n",
      "Retrieval-Augmented Generation (RAG) systems are a revolutionary ar-\n",
      "chitectural approach that surpasses the constraints of traditional language\n",
      "models by incorporating external retrieval as a primary inductive ...\n",
      "\n",
      "--- Source 10 ---\n",
      "ğŸ“„ Page: 10\n",
      "ğŸ“ File: Data\\RAG-Papers-2025\\Engineering the RAG Stack.pdf\n",
      "ğŸ“‹ Title: Engineering the RAG Stack: A Comprehensive Review of the Architecture and Trust Frameworks for Retrieval-Augmented Generation Systems\n",
      "ğŸ‘¤ Author: Dean Wampler; Dave Nielson; Alireza Seddighi\n",
      "ğŸ”¢ Chunk ID: 26\n",
      "â­ Score: 0.019127054139971733\n",
      "\n",
      "ğŸ“– Content Preview:\n",
      "identify a set of top,k documents D1, ..., Dk from a corpus C. The following\n",
      "is the formal calculation:\n",
      "score(q, d) = fq(q)âŠ¤fd(d)\n",
      "where fq and fd are the encoding functions for query and document, re-\n",
      "spectively.\n",
      "Subsequently, the generator receives the retrieved documents\n",
      "and linearly combines them...\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "top_k = 10\n",
    "\n",
    "rag_chain = setup_rag_inference(embeddings, top_k)\n",
    "\n",
    "query_rag_system(\n",
    "    rag_chain,\n",
    "    \"\"\"Generate a detailed summary along with key findings for the research paper starting from \n",
    "    the begining till the ending. Also provide citations and references if possible.\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5626c8a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
